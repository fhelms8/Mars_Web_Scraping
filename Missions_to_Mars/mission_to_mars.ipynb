{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import pymongo\n",
    "import os\n",
    "import time \n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 93.0.4577\n",
      "Get LATEST driver version for 93.0.4577\n",
      "Driver [C:\\Users\\fhelm\\.wdm\\drivers\\chromedriver\\win32\\93.0.4577.63\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nasa Mars News\n",
    "#### Create a Jupyter Notebook file called mission_to_mars.ipynb and use this to complete all of your scraping and analysis tasks.                                     The following outlines what you need to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.commerce_db\n",
    "collection = db.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup = bs(browser.html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the columns that contain the title and paragraph texts\n",
    "results = soup.find_all('div', class_='list_text')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------\n",
      "\n",
      "NASA Perseverance Mars Rover Scientists Train in the Nevada Desert\n",
      "Body:\n",
      "Team members searched for signs of ancient microscopic life there, just as NASA's latest rover will on the Red Planet next year.\n",
      "\n",
      "-----------------\n",
      "\n",
      "With Mars Methane Mystery Unsolved, Curiosity Serves Scientists a New One: Oxygen\n",
      "Body:\n",
      "For the first time in the history of space exploration, scientists have measured the seasonal changes in the gases that fill the air directly above the surface of Gale Crater on Mars. \n",
      "\n",
      "-----------------\n",
      "\n",
      "NASA Wins 4 Webbys, 4 People's Voice Awards\n",
      "Body:\n",
      "Winners include the JPL-managed \"Send Your Name to Mars\" campaign, NASA's Global Climate Change website and Solar System Interactive.\n",
      "\n",
      "-----------------\n",
      "\n",
      "3 Things We've Learned From NASA's Mars InSight \n",
      "Body:\n",
      "Scientists are finding new mysteries since the geophysics mission landed two years ago.\n",
      "\n",
      "-----------------\n",
      "\n",
      "Robotic Toolkit Added to NASA's Mars 2020 Rover\n",
      "Body:\n",
      "The bit carousel, which lies at the heart of the rover's Sample Caching System, is now aboard NASA's newest rover. \n",
      "\n",
      "-----------------\n",
      "\n",
      "NASA Invites Students to Name Mars 2020 Rover\n",
      "Body:\n",
      "Through Nov. 1, K-12 students in the U.S. are encouraged to enter an essay contest to name NASA's next Mars rover.\n",
      "\n",
      "-----------------\n",
      "\n",
      "NASA's Curiosity Mars Rover Snaps Its Highest-Resolution Panorama Yet\n",
      "Body:\n",
      "To go along with the stunning 1.8-billion-pixel image, a new video offers a sweeping view of the Red Planet.\n",
      "\n",
      "-----------------\n",
      "\n",
      "Scientists Explore Outback as Testbed for Mars \n",
      "Body:\n",
      "Australia provides a great place for NASA's Mars 2020 and the ESA-Roscosmos ExoMars scientists to hone techniques in preparation for searching for signs ancient life on Mars.\n",
      "\n",
      "-----------------\n",
      "\n",
      "Sensors on Mars 2020 Spacecraft Answer Long-Distance Call From Earth\n",
      "Body:\n",
      "Instruments tailored to collect data during the descent of NASA's next rover through the Red Planet's atmosphere have been checked in flight.\n",
      "\n",
      "-----------------\n",
      "\n",
      "From JPL's Mailroom to Mars and Beyond\n",
      "Body:\n",
      "Bill Allen has thrived as the mechanical systems design lead for three Mars rover missions, but he got his start as a teenager sorting letters for the NASA center.\n",
      "\n",
      "-----------------\n",
      "\n",
      "Mars Is Getting a New Robotic Meteorologist\n",
      "Body:\n",
      "Sensors on NASA's Perseverance will help prepare for future human exploration by taking weather measurements and studying dust particles.\n",
      "\n",
      "-----------------\n",
      "\n",
      "NASA Engineers Checking InSight's Weather Sensors\n",
      "Body:\n",
      "An electronics issue is suspected to be preventing the sensors from sharing their data about Mars weather with the spacecraft.\n",
      "\n",
      "-----------------\n",
      "\n",
      "NASA's Mars 2020 Will Hunt for Microscopic Fossils\n",
      "Body:\n",
      "A new paper identifies a ring of minerals at the rover's landing site that are ideal for fossilizing microbial life.\n",
      "\n",
      "-----------------\n",
      "\n",
      "Mars 2020 Stands on Its Own Six Wheels\n",
      "Body:\n",
      "In time-lapse video, taken at JPL, captures the first time NASA's Mars 2020 rover carries its full weight on its legs and wheels.\n",
      "\n",
      "-----------------\n",
      "\n",
      "8 Martian Postcards to Celebrate Curiosity's Landing Anniversary\n",
      "Body:\n",
      "The NASA rover touched down eight years ago, on Aug. 5, 2012, and will soon be joined by a second rover, Perseverance.\n"
     ]
    }
   ],
   "source": [
    "# Loop through returned results\n",
    "for result in results:\n",
    "    \n",
    "    # Retrieve the thread title\n",
    "    title = result.find('div', class_='content_title')\n",
    "    \n",
    "    \n",
    "    # Access the thread's text content\n",
    "    title_text = title.text\n",
    "   \n",
    "\n",
    "    try:\n",
    "        # Access the thread with CSS selectors\n",
    "        thread = result.find('div', class_='article_teaser_body') \n",
    "        \n",
    "\n",
    "        # The number of comments made in the thread\n",
    "        teaser_body = thread.text.lstrip()\n",
    "        \n",
    "        # Run teaser_body & title \n",
    "        if (teaser_body):\n",
    "            print('\\n-----------------\\n')\n",
    "            print(title_text)\n",
    "            print('Body:')\n",
    "            print(teaser_body)\n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "#### Visit the url for the Featured Space Image\n",
    "\n",
    "#### Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url.\n",
    "\n",
    "#### Make sure to find the image url to the full size .jpg image.\n",
    "\n",
    "#### Make sure to save a complete url string for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# website: https://spaceimages-mars.com/\n",
    "# Use splinter to navigate the site and find the image url for the current Featured \n",
    "# Mars Image and assign the url string to a variable called featured_image_url\n",
    "\n",
    "url = \"https://spaceimages-mars.com/\"\n",
    "browser.visit(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(browser.html, 'lxml')\n",
    "\n",
    "html = browser.html\n",
    "img_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = soup.find_all('div', class_='header')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/featured/mars3.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the row that contain the picture url\n",
    "header_image = soup.find('img', class_='headerimage fade-in').get('src')\n",
    "header_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spaceimages-mars.com/image/featured/mars3.jpg\n"
     ]
    }
   ],
   "source": [
    "featured_image_url = url + header_image\n",
    "print(featured_image_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "#### Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "#### Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url https://galaxyfacts-mars.com/\n",
    "# Give url variable name\n",
    "url = 'https://galaxyfacts-mars.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Plant 1</th>\n",
       "      <th>Plant 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mars - Earth Comparison</td>\n",
       "      <td>Mars</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diameter:</td>\n",
       "      <td>6,779 km</td>\n",
       "      <td>12,742 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "      <td>5.97 × 10^24 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Distance from Sun:</td>\n",
       "      <td>227,943,824 km</td>\n",
       "      <td>149,598,262 km</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Description          Plant 1          Plant 2\n",
       "0  Mars - Earth Comparison             Mars            Earth\n",
       "1                Diameter:         6,779 km        12,742 km\n",
       "2                    Mass:  6.39 × 10^23 kg  5.97 × 10^24 kg\n",
       "3                   Moons:                2                1\n",
       "4       Distance from Sun:   227,943,824 km   149,598,262 km"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table and merge into a df\n",
    "tables = pd.read_html(url)\n",
    "df = tables[0]\n",
    "df.columns = [\"Description\",\"Plant 1\",\"Plant 2\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Description</th>\\n      <th>Plant 1</th>\\n      <th>Plant 2</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Mars - Earth Comparison</td>\\n      <td>Mars</td>\\n      <td>Earth</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Diameter:</td>\\n      <td>6,779 km</td>\\n      <td>12,742 km</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Mass:</td>\\n      <td>6.39 × 10^23 kg</td>\\n      <td>5.97 × 10^24 kg</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Moons:</td>\\n      <td>2</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Distance from Sun:</td>\\n      <td>227,943,824 km</td>\\n      <td>149,598,262 km</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Length of Year:</td>\\n      <td>687 Earth days</td>\\n      <td>365.24 days</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Temperature:</td>\\n      <td>-87 to -5 °C</td>\\n      <td>-88 to 58°C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cover df into html \n",
    "html_table = df.to_html()\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Description</th>      <th>Plant 1</th>      <th>Plant 2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Mars - Earth Comparison</td>      <td>Mars</td>      <td>Earth</td>    </tr>    <tr>      <th>1</th>      <td>Diameter:</td>      <td>6,779 km</td>      <td>12,742 km</td>    </tr>    <tr>      <th>2</th>      <td>Mass:</td>      <td>6.39 × 10^23 kg</td>      <td>5.97 × 10^24 kg</td>    </tr>    <tr>      <th>3</th>      <td>Moons:</td>      <td>2</td>      <td>1</td>    </tr>    <tr>      <th>4</th>      <td>Distance from Sun:</td>      <td>227,943,824 km</td>      <td>149,598,262 km</td>    </tr>    <tr>      <th>5</th>      <td>Length of Year:</td>      <td>687 Earth days</td>      <td>365.24 days</td>    </tr>    <tr>      <th>6</th>      <td>Temperature:</td>      <td>-87 to -5 °C</td>      <td>-88 to 58°C</td>    </tr>  </tbody></table>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up\n",
    "clean_html = html_table.replace('\\n', '')\n",
    "clean_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file as html \n",
    "df.to_html('mars_table.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "\n",
    "#### Visit the astrogeology site here to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "#### You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "#### Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "\n",
    "#### Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to contain all planets img & title \n",
    "planet_dict = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cerberus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title:Cerberus Hemisphere Enhanced',\n",
       " 'img_url:https://marshemispheres.com/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# url https://marshemispheres.com/\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#Click on url link \n",
    "browser.links.find_by_partial_text('Cerberus').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "# print(soup.prettify())\n",
    "\n",
    "#Pull the link that contains the full image \n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    "\n",
    "#Pull Hemisphere title \n",
    "cerberus_title = soup.find('h2', class_='title').text\n",
    "# print(cerberus_title)\n",
    "\n",
    "# Combine url & img link to make full html link=\n",
    "cerberus_img = url + img_link\n",
    "# print(cerberus_img)\n",
    "\n",
    "browser.back()\n",
    "#Create dictionaries to the img url and title \n",
    "\n",
    "cerberus_dict = {'title:' + cerberus_title, 'img_url:' + cerberus_img}\n",
    "planet_dict.append(cerberus_dict)\n",
    "\n",
    "list(cerberus_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schiaparelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_url:https://marshemispheres.com/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg',\n",
       " 'title:Schiaparelli Hemisphere Enhanced']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url https://marshemispheres.com/\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#Click on url link \n",
    "browser.links.find_by_partial_text('Schiaparelli').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "# print(soup.prettify())\n",
    "\n",
    "#Pull the link that contains the full image \n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    "\n",
    "#Pull Hemisphere title \n",
    "schiaparelli_title = soup.find('h2', class_='title').text\n",
    "# print(cerberus_title)\n",
    "\n",
    "# Combine url & img link to make full html link=\n",
    "schiaparelli_img = url + img_link\n",
    "# print(cerberus_img)\n",
    "\n",
    "browser.back()\n",
    "#Create dictionaries to the img url and title \n",
    "\n",
    "schiaparelli_dict = {'title:' + schiaparelli_title, 'img_url:' + schiaparelli_img}\n",
    "planet_dict.append(schiaparelli_dict)\n",
    "\n",
    "list(schiaparelli_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syrtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_url:https://marshemispheres.com/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg',\n",
       " 'title:Syrtis Major Hemisphere Enhanced']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url https://marshemispheres.com/\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#Click on url link \n",
    "browser.links.find_by_partial_text('Syrtis').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "# print(soup.prettify())\n",
    "\n",
    "#Pull the link that contains the full image \n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    "\n",
    "#Pull Hemisphere title \n",
    "syrtis_title = soup.find('h2', class_='title').text\n",
    "# print(cerberus_title)\n",
    "\n",
    "# Combine url & img link to make full html link=\n",
    "syrtis_img = url + img_link\n",
    "# print(cerberus_img)\n",
    "\n",
    "browser.back()\n",
    "#Create dictionaries to the img url and title \n",
    "\n",
    "syrtis_dict = {'title:' + syrtis_title, 'img_url:' + syrtis_img}\n",
    "planet_dict.append(syrtis_dict)\n",
    "\n",
    "list(syrtis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valles Marineris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title:Valles Marineris Hemisphere Enhanced',\n",
       " 'img_url:https://marshemispheres.com/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url https://marshemispheres.com/\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#Click on url link \n",
    "browser.links.find_by_partial_text('Valles Marineris').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "# print(soup.prettify())\n",
    "\n",
    "#Pull the link that contains the full image \n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    "\n",
    "#Pull Hemisphere title \n",
    "valles_title = soup.find('h2', class_='title').text\n",
    "# print(cerberus_title)\n",
    "\n",
    "# Combine url & img link to make full html link=\n",
    "valles_img = url + img_link\n",
    "# print(cerberus_img)\n",
    "\n",
    "browser.back()\n",
    "#Create dictionaries to the img url and title \n",
    "\n",
    "valles_dict = {'title:' + valles_title, 'img_url:' + valles_img}\n",
    "planet_dict.append(valles_dict)\n",
    "\n",
    "list(valles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'img_url:https://marshemispheres.com/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg',\n",
       "  'title:Cerberus Hemisphere Enhanced'},\n",
       " {'img_url:https://marshemispheres.com/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg',\n",
       "  'title:Schiaparelli Hemisphere Enhanced'},\n",
       " {'img_url:https://marshemispheres.com/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg',\n",
       "  'title:Syrtis Major Hemisphere Enhanced'},\n",
       " {'img_url:https://marshemispheres.com/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg',\n",
       "  'title:Valles Marineris Hemisphere Enhanced'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(planet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
